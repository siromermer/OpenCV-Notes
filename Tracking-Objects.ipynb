{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4f60bd-d6bb-49e8-85be-74974a89f6be",
   "metadata": {},
   "source": [
    "## Detecting Moving Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811388e2-7105-4046-b0d2-9b0b5de02239",
   "metadata": {},
   "source": [
    "There are many ways to track objects in a video, all of them fulfilling a slightly\r\n",
    "different purpose. For example, you may want to track anything that moves, in\r\n",
    "which case differences between frames are going to be of help; you may want to\r\n",
    "track a hand moving in a video, in which case Meanshift based on the color of the\r\n",
    "skin is the most appropriate solution; you may want to track a particular object of\r\n",
    "which you know the aspect, in which case techniques such as template matching\r\n",
    "will be of help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a45b1-cea4-4f52-bddd-7a17826330f0",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1738c3c-391e-4b8a-8246-6865c87b2197",
   "metadata": {},
   "source": [
    "## Basic Motion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87ac96-466d-4091-8e27-e7947429176e",
   "metadata": {},
   "source": [
    "The first and most intuitive solution is to calculate the differences between frames, or\r\n",
    "between a frame considered \"background\" and all the other frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a2bde0-5fcb-47ca-89a6-b3619a869a97",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# convert grayscale and blur image\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m gray_frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m gray_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray_frame, (\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m21\u001b[39m), \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# in each video feed there will be noise and that noises may be detected as motion  to prevent it use cv2.GaussianBlur\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# calculate differences\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "camera = cv2.VideoCapture(\"resources/cars.mp4\")\n",
    "background = None\n",
    "\n",
    "es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,4)) # for dilate \n",
    "\n",
    "while (True):\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    # set first frame as a background\n",
    "    if background is None:\n",
    "        background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        background = cv2.GaussianBlur(background, (21, 21), 0)\n",
    "        continue\n",
    "\n",
    "    # convert grayscale and blur image\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0) # in each video feed there will be noise and that noises may be detected as motion  to prevent it use cv2.GaussianBlur\n",
    "\n",
    "    # calculate differences\n",
    "    diff = cv2.absdiff(background, gray_frame)\n",
    "    diff = cv2.threshold(diff, 50, 255, cv2.THRESH_BINARY)[1] # it returns two parameter first one is useless\n",
    "    diff = cv2.dilate(diff, es, iterations = 2) # dilating can also act as a noise filter\n",
    "    \n",
    "    cnts, hierarchy = cv2.findContours(diff.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for c in cnts:\n",
    "        if cv2.contourArea(c) < 1500: # only display contours for rectangles greater than an arbitrary threshold\n",
    "             continue\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"contours\", frame)\n",
    "    cv2.imshow(\"dif\", diff)\n",
    "\n",
    "    if cv2.waitKey(17) & 0xff == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488ee8c-9eb6-4949-ae6a-93d44b815d33",
   "metadata": {},
   "source": [
    "• cv2.findContours: This function computes the contours of subjects in an image<br>\n",
    "• cv2.boundinRect: This function calculates their bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a154e6ba-eaff-4a9c-9991-6695c1e87418",
   "metadata": {},
   "source": [
    "Conclusion :\n",
    "this technique is quite fast to implement but it is not that suitable for applications <br>\n",
    "because first you need to set deafult frame as a background and probably background is not going to stay constant in your applications .<br> Imagine your are detecting cars , setting deafult background is not going to effective because cars are moving everything is changing , light is changing ....<br>\n",
    "That's where Background subtractors come into play"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222d7a7-d697-4785-b4a7-a6d07283757d",
   "metadata": {},
   "source": [
    "<br><br><br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89be51-3c51-432d-b303-c0fb615e7c84",
   "metadata": {},
   "source": [
    "##  Background subtractors – KNN, MOG2, and GMG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef782fc8-7401-45d8-a8a0-cd864e287e1e",
   "metadata": {},
   "source": [
    "There are three background subtractors available in OpenCV 3: \n",
    "1. K-Nearest Neighbors (KNN) ++ \n",
    "2. Mixture of Gaussians (MOG2) ++  \n",
    "3. Geometric Multigrid (GMG) -- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4f8cb-5469-4af2-8f6a-8fe52fdbbf8e",
   "metadata": {},
   "source": [
    "BackgroundSubtractor classes are specifically built with video analysis in mind, which means that the OpenCV BackgroundSubtractor classes \"learn\" something about the environment with every frame<br><br>\n",
    "Another fundamental (and frankly, quite amazing) feature of the BackgroundSubtractor classes is the ability to compute shadow . This is absolutely vital for an accurate reading of video frames; by detecting shadows, you can exclud shadow areas (by thresholding them) from the objects you detected, and concentra e on the real featuress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37499b-fefe-4317-b8ef-9f767fa87e7f",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e81aa-97d3-464c-9911-64090ca72d2e",
   "metadata": {},
   "source": [
    "comparison : https://www.jetir.org/papers/JETIR1805563.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e80fc35-df52-4946-9d3b-4ccdd180bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# KNN\n",
    "KNN_subtractor = cv2.createBackgroundSubtractorKNN(detectShadows = True) # detectShadows=True : exclude shadow areas from the objects you detected\n",
    "\n",
    "# MOG2\n",
    "MOG2_subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows = True) # exclude shadow areas from the objects you detected\n",
    "\n",
    "# choose your subtractor\n",
    "bg_subtractor=MOG2_subtractor\n",
    "\n",
    "camera = cv2.VideoCapture(\"resources/cars.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    # Every frame is used both for calculating the foreground mask and for updating the background. \n",
    "    foreground_mask = bg_subtractor.apply(frame)\n",
    "\n",
    "    # threshold if it is bigger than 240 pixel is equal to 255 if smaller pixel is equal to 0\n",
    "    # create binary image , it contains only white and black pixels\n",
    "    ret , treshold = cv2.threshold(foreground_mask.copy(), 120, 255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # reduce noise\n",
    "    dilated = cv2.dilate(treshold,cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)),iterations = 2)\n",
    "    \n",
    "     # find contours \n",
    "    contours, hier = cv2.findContours(dilated,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # check every contour if are exceed certain value draw bounding boxes\n",
    "    for contour in contours:\n",
    "        # if area exceed certain value then draw bounding boxes\n",
    "        if cv2.contourArea(contour) > 350:\n",
    "            (x,y,w,h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Subtractor\", foreground_mask)\n",
    "    cv2.imshow(\"threshold\", treshold)\n",
    "    cv2.imshow(\"dilated\", dilated)\n",
    "    cv2.imshow(\"detection\", frame)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xff == 27:\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edf0726d-a0b6-45ff-a4a8-c335b32f023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944857de-0087-4531-8b1b-cacfd92431f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.createBackgroundSubtractorMOG2();\n",
    "cv2.createBackgroundSubtractorKNN();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f27eabf1-fc6d-4ff0-81a8-cba6afc74d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# KNN\n",
    "KNN_subtractor = cv2.createBackgroundSubtractorKNN(detectShadows = True) # exclude shadow areas from the objects you detected\n",
    "\n",
    "# MOG\n",
    "MOG2_subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows = True) # exclude shadow areas from the objects you detected\n",
    "\n",
    "# choose your subtractor\n",
    "bg_subtractor=MOG2_subtractor\n",
    "\n",
    "camera = cv2.VideoCapture(\"resources/bird.mp4\")\n",
    "\n",
    "frame_width = int(camera.get(3)) \n",
    "frame_height = int(camera.get(4)) \n",
    "   \n",
    "size = (frame_width, frame_height) \n",
    "   \n",
    "# Below VideoWriter object will create \n",
    "# a frame of above defined The output  \n",
    "# is stored in 'filename.avi' file. \n",
    "result = cv2.VideoWriter('birds.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, size) \n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    # Every frame is used both for calculating the foreground mask and for updating the background. \n",
    "    foreground_mask = bg_subtractor.apply(frame)\n",
    "\n",
    "    # threshold if it is bigger than 240 pixel is equal to 255 if smaller pixel is equal to 0\n",
    "    ret , treshold = cv2.threshold(foreground_mask.copy(), 240, 255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    dilated = cv2.dilate(treshold,cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)),iterations = 2)\n",
    "    \n",
    "    contours, hier = cv2.findContours(dilated,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 100:\n",
    "            (x,y,w,h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255), 3)\n",
    "\n",
    "    cv2.imshow(\"Subtractor\", foreground_mask)\n",
    "    cv2.imshow(\"threshold\", treshold)\n",
    "    cv2.imshow(\"detection\", frame)\n",
    "\n",
    "    result.write(frame)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xff == 27:\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a74e3-cb84-4003-bb0d-3553446ff167",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ba5d2-2d11-4936-8e0e-ea3d95ff848a",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b0397-5634-4950-9377-e97d0becba0f",
   "metadata": {},
   "source": [
    "## Meanshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8c8d0-c48f-41f1-a21b-ab328cf015a5",
   "metadata": {},
   "source": [
    "Meanshift is an algorithm that tracks objects by finding\r\n",
    "the maximum density of a discrete sample of a probability function (in our case, a\r\n",
    "region of interest in an image) and recalculating it at the next frame, which gives the\r\n",
    "algorithm an indication of the direction in which the object has moved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca05040-83a0-4562-8768-1202dee1ba72",
   "metadata": {},
   "source": [
    "2 very important built-in functions of \n",
    "OpenCV: calcHist and calcBackProject.\r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1d2d8-5283-4d01-b53f-f79ed3a2ad4b",
   "metadata": {},
   "source": [
    "#### calcHist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9145f-0ea6-4b7d-94bb-045d8788b8ca",
   "metadata": {},
   "source": [
    "The function, calcHist, calculates color histograms of an image .<br>\n",
    "A color histogram \n",
    "is a representation of the color distribution of an image. On the x axis of th \r\n",
    "representation, we have color values, and on the y axis, we have the numb r\r\n",
    "of pixels corresponding to the color values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25125eae-e9f9-4489-9b59-d55d4dc56ad2",
   "metadata": {},
   "source": [
    "#### calcBackProject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49863a4-5bf5-46c1-ae90-8a3dfc16bb65",
   "metadata": {},
   "source": [
    "The other function that covers a vital role in the Meanshift algorithm (but not only this) is calcBackProject, which is short for histogram back projection (calculation)<br>\n",
    "A histogram back projection is so called because it takes a histogram and projects\n",
    "it back onto an image, with the result being the probability that each pixel will\n",
    "belong to the image that generated the histogram in the first place<br>\n",
    "Therefore,\n",
    "calcBackProject gives a probability estimation that a certain image is equal or\r\n",
    "similar to a model image (from which the original histogram was generated)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f3291-5df9-4f7e-8b94-348494b2ff9d",
   "metadata": {},
   "source": [
    "cv2.calcBackProject() işlevi, bir görüntüdeki bir nesnenin olası konumunu tahmin etmek için kullanılan bir histogram temelli geri projeksiyon yöntemini uygular. Bu işlevin çıktısı, nesnenin olası konumunu belirlemek için kullanılan bir olasılık haritasıdır.\r\n",
    "\r\n",
    "Bu olasılık haritası, nesnenin bulunma olasılığını belirtir ve genellikle piksel değerleri veya belirli bölgelerin yoğunluğu ile temsil edilir. Yani, çıktı bir koordinat değil, her pikselin nesnenin olası konumuna olan katkısını gösteren bir 2D görüntüdür.\r\n",
    "\r\n",
    "Daha sonra, bu olasılık haritası, cv2.meanShift() gibi bir izleme algoritması tarafından kullanılabilir ve nesnenin mevcut konumu hesaplanabilir. Bu algoritma, belirli bir başlangıç konumundan hareket ederek olasılık haritasındaki maksimum yoğunluğa yönelir ve bu şekilde nesnenin konumunu belirler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3befab1b-0eb2-40c6-b192-d4c7a939c654",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2aad69-0098-4f0d-bdc5-6cda8a2896df",
   "metadata": {},
   "source": [
    "The calcHist function extracts a color histogram from an image, giving a statistical\r\n",
    "representation of the colors in an image, and calcBackProject helps in calculating\r\n",
    "the probability of each pixel of an image belonging to the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba3e50-969d-4eaf-a4e6-d7cea5a3baa6",
   "metadata": {},
   "source": [
    "!! Problem of Meanshift : : the size of the window does not change with the size of the object in the\r\n",
    "frames being tracked<br>\n",
    "CAMShift solves that problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66baed2c-f989-4bf0-8bd7-47f939680607",
   "metadata": {},
   "source": [
    "meanshift algorithm example : <br>\n",
    "https://github.com/siromermer/Object-Tracker-Meanshift-Algorithm/blob/main/meanshift.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c08bfad-24e7-48be-bd73-274575a59a02",
   "metadata": {},
   "source": [
    "<BR><BR><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a67bf-e53c-4f22-8289-f33831cb572b",
   "metadata": {},
   "source": [
    "## CAMShift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757c45e-5d0e-4f4a-a5e5-e8f30704d5e4",
   "metadata": {},
   "source": [
    "its implementation is similar to the meanshift , main difference is : after the call to CamShift,\r\n",
    "the rectangle is drawn with a particular rotation that follows the rotation of the\r\n",
    "object being tracked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f83a93-c63a-4b16-9ad1-3064800de8f1",
   "metadata": {},
   "source": [
    "camshift example : https://github.com/siromermer/Object-Tracker-Meanshift-Algorithm/blob/main/camshift.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31573dfc-31ce-47b9-b24a-ba5a440dec0b",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c605481-fd47-4787-a127-068492781d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e63ea-d5a1-4565-b3e7-380de0458496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8aa97-0596-4411-8883-059971cc6523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
